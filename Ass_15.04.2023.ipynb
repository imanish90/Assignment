{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdcc30d-4983-44de-a72a-58846f0583f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fae7423-aba0-4145-8790-8a887e6a30d8",
   "metadata": {},
   "outputs": [],
   "source": [
    " Here's an outline of the pipeline that you can use for your machine learning project:\n",
    "\n",
    "Automated feature selection: You can use various feature selection methods like SelectKBest, SelectFromModel, Recursive Feature Elimination, etc. to identify the important features in the dataset. Here's an example of how you can use SelectKBest to select the top 10 features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6954eaa-0193-4fcc-b286-e159d493c9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "selector = SelectKBest(score_func=f_classif, k=10)\n",
    "X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "X_test_selected = selector.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c129b2-d805-4051-9197-b41e215ccc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "Numerical pipeline: For the numerical columns, you can use SimpleImputer to impute the missing values with the mean of the column values, and StandardScaler to scale the numerical columns using standardisation. Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abb82fc-c479-46c0-8bd4-41d3b5b12e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"mean\")),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ab23bd-8ec6-476a-94e7-c036c99d4d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Categorical pipeline: For the categorical columns, you can use SimpleImputer to impute the missing values with the most frequent value of the column, and OneHotEncoder to one-hot encode the categorical columns. Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fa00e8-7cf5-4a3e-bfd0-9cbc83dee365",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "cat_pipeline = Pipeline([        ('imputer', SimpleImputer(strategy=\"most_frequent\")),        ('one_hot', OneHotEncoder()),    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246ee5c8-4737-4ed8-8253-a1267dd35a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "ColumnTransformer: Use ColumnTransformer to combine the numerical and categorical pipelines. Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b10868f-4458-4744-b108-38b1a1eb7061",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_attribs = ['num_col1', 'num_col2', ...]\n",
    "cat_attribs = ['cat_col1', 'cat_col2', ...]\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_attribs),\n",
    "        (\"cat\", cat_pipeline, cat_attribs),\n",
    "    ])\n",
    "X_train_transformed = full_pipeline.fit_transform(X_train)\n",
    "X_test_transformed = full_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1ad96c-01e6-4c91-bada-a68c8a9ec744",
   "metadata": {},
   "outputs": [],
   "source": [
    "Random Forest Classifier: Use Random Forest Classifier to build the final model. Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2c0274-da66-4c8e-a444-cd82fbd051ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier()\n",
    "rf_clf.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02e20b6-59ee-4683-b35a-9dd8a5a73428",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model Evaluation: Finally, evaluate the accuracy of the model on the test dataset. Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc164d8a-cd05-4664-a963-bf2f48d37c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = rf_clf.predict(X_test_transformed)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19874da9-8cb1-4108-b39d-a07a1053c960",
   "metadata": {},
   "outputs": [],
   "source": [
    "Overall, this pipeline should help you automate the feature engineering process and handle the missing values in your dataset. The interpretation of the results and possible improvements of the pipeline depend on the specific problem and dataset you are working with. However, some general suggestions are to try different feature selection methods, experiment with different imputation and scaling techniques, and tune the hyperparameters of the Random Forest Classifier to optimize the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc16854-85c5-4724-9bb7-0f702feef1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20345ed-74fa-48f9-ac96-3ea380ca22e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline that includes a Random Forest Classifier and a Linear Regression model, and use a Voting Classifier to combine their predictions and improve the accuracy on the iris dataset.\n",
    "\n",
    "Here's an outline of the pipeline that you can use:\n",
    "\n",
    "Load the iris dataset using the load_iris() function from the scikit-learn library.\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db4c0c6-3cfa-489d-9ca2-beb22dd50912",
   "metadata": {},
   "outputs": [],
   "source": [
    "Split the dataset into training and test sets using train_test_split() function from the scikit-learn library.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5c173e-53ac-4d02-84e0-ef53c036d8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "Create pipelines for the Random Forest Classifier and Linear Regression models.\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "rf_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"mean\")),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "        ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ])\n",
    "\n",
    "lr_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"mean\")),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "        ('lr', LinearRegression()),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f70a8db-ed63-4d25-a6ab-7c86ca5a5cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "Use a Voting Classifier to combine the predictions of the Random Forest Classifier and Linear Regression models.\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "        estimators=[('rf', rf_pipeline), ('lr', lr_pipeline)],\n",
    "        voting='hard'\n",
    "    )\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eceb16ad-638c-4f18-9fa7-b661bf36c849",
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluate the accuracy of the Voting Classifier on the test dataset.\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0723864-3da2-45c4-8295-d1ed5ee537c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(Optional) Save the pipeline to a GitHub repository.\n",
    "You can use the GitPython library to create a Git repository, commit the pipeline code to the repository, and push it to a GitHub repository.\n",
    "\n",
    "!pip install gitpython\n",
    "\n",
    "import git\n",
    "\n",
    "# Initialize the Git repository\n",
    "repo = git.Repo.init('my_repo')\n",
    "\n",
    "# Create a file to store the pipeline code\n",
    "with open('my_pipeline.py', 'w') as f:\n",
    "    f.write(\"# Pipeline code here\")\n",
    "\n",
    "# Add the file to the Git repository\n",
    "repo.index.add(['my_pipeline.py'])\n",
    "\n",
    "# Commit the changes to the repository\n",
    "repo.index.commit(\"Initial commit\")\n",
    "\n",
    "# Add the remote GitHub repository as the origin\n",
    "remote_url = \"https://github.com/yourusername/your-repo.git\"\n",
    "origin = repo.create_remote('origin', remote_url)\n",
    "\n",
    "# Push the changes to the GitHub repository\n",
    "origin.push(refspec='HEAD:main')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e996b7e-f57f-49d6-8eac-105ae99038aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Overall, this pipeline should help you combine the predictions of a Random Forest Classifier and Linear Regression model using a Voting Classifier and improve the accuracy on the iris dataset. You can experiment with different models and hyperparameters, and tune the pipeline to optimize the performance on your specific problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca0342f-db90-4646-b77c-e80a64e7dcbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
