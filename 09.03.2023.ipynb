{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ee9285-c08f-4515-9c2c-e859ae7a823f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a3d3f3-5afb-4752-911b-6e2331d7222e",
   "metadata": {},
   "outputs": [],
   "source": [
    "The Probability Mass Function (PMF) and Probability Density Function (PDF) are two types of functions that are used to describe the probability distribution of a random variable.\n",
    "\n",
    "The PMF is used for discrete random variables and gives the probability of each possible value that the random variable can take. The PMF is defined as:\n",
    "\n",
    "P(X = x) = f(x)\n",
    "\n",
    "where X is the random variable and x is a specific value that X can take. The function f(x) gives the probability that X takes the value x.\n",
    "\n",
    "For example, suppose we roll a fair six-sided die. The random variable X can take the values 1, 2, 3, 4, 5, or 6 with equal probability. The PMF of X is:\n",
    "\n",
    "P(X = 1) = 1/6\n",
    "P(X = 2) = 1/6\n",
    "P(X = 3) = 1/6\n",
    "P(X = 4) = 1/6\n",
    "P(X = 5) = 1/6\n",
    "P(X = 6) = 1/6\n",
    "\n",
    "The PDF, on the other hand, is used for continuous random variables and gives the probability density at each possible value of the random variable. Unlike the PMF, which gives the actual probability of each value, the PDF gives the probability density, which is the probability per unit of the random variable. The PDF is defined as:\n",
    "\n",
    "f(x) = dF(x) / dx\n",
    "\n",
    "where F(x) is the cumulative distribution function (CDF) of the random variable X, which gives the probability that X takes a value less than or equal to x. The function f(x) is the derivative of the CDF with respect to x.\n",
    "\n",
    "For example, suppose we have a normal distribution with mean μ = 0 and standard deviation σ = 1. The PDF of this distribution is:\n",
    "\n",
    "f(x) = (1 / (σ * sqrt(2π))) * e^(-((x - μ)^2) / (2σ^2))\n",
    "\n",
    "This function gives the probability density at each possible value of X. Since the normal distribution is a continuous distribution, the probability of X taking any specific value is actually 0. Instead, the PDF tells us the relative likelihood of X being in a certain range of values.\n",
    "\n",
    "In summary, the PMF is used for discrete random variables and gives the probability of each possible value, while the PDF is used for continuous random variables and gives the probability density at each possible value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029085e5-a5a5-4c65-85fd-ee2815edc2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a7c125-cf64-451a-95e2-fccaeb5807ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "The Cumulative Distribution Function (CDF) is a function that gives the probability that a random variable X is less than or equal to a certain value x. The CDF is defined as:\n",
    "\n",
    "F(x) = P(X <= x)\n",
    "\n",
    "The CDF can be used for both discrete and continuous random variables. For discrete random variables, the CDF is a step function that increases by the probability mass at each possible value of the random variable. For continuous random variables, the CDF is a continuous function that increases smoothly from 0 to 1.\n",
    "\n",
    "As an example, suppose we have a fair six-sided die. The random variable X is the result of rolling the die, which can take the values 1, 2, 3, 4, 5, or 6 with equal probability. The CDF of X is:\n",
    "\n",
    "F(x) = P(X <= x)\n",
    "= 0 if x < 1\n",
    "= 1/6 if 1 <= x < 2\n",
    "= 2/6 = 1/3 if 2 <= x < 3\n",
    "= 3/6 = 1/2 if 3 <= x < 4\n",
    "= 4/6 = 2/3 if 4 <= x < 5\n",
    "= 5/6 if 5 <= x < 6\n",
    "= 1 if x >= 6\n",
    "\n",
    "For example, the probability that X is less than or equal to 3 is:\n",
    "\n",
    "F(3) = P(X <= 3) = 1/2\n",
    "\n",
    "The CDF is used for a variety of purposes in probability theory and statistics. One important use of the CDF is to calculate probabilities of events. For example, if we want to know the probability that X is between a and b, we can use the CDF:\n",
    "\n",
    "P(a < X <= b) = F(b) - F(a)\n",
    "\n",
    "Another important use of the CDF is to generate random numbers that follow a given probability distribution. This can be done by inverting the CDF. That is, if we have a random number u that is uniformly distributed between 0 and 1, we can use the inverse CDF to generate a random number X that follows the desired probability distribution:\n",
    "\n",
    "X = F^(-1)(u)\n",
    "\n",
    "where F^(-1) is the inverse CDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ed0b18-7ef3-4ac9-8fa9-e4321acabc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addc68d0-b36a-48d5-8c57-1720e907e5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "The normal distribution is a commonly used probability distribution that can be used as a model for many real-world situations. Here are a few examples:\n",
    "\n",
    "Heights of people: The heights of people in a population tend to follow a normal distribution.\n",
    "\n",
    "Test scores: The scores on a standardized test tend to follow a normal distribution.\n",
    "\n",
    "Errors in measurement: The errors in measurement when taking a large number of measurements tend to follow a normal distribution.\n",
    "\n",
    "The normal distribution is characterized by two parameters: the mean (µ) and the standard deviation (σ). The mean represents the center of the distribution and the standard deviation represents the spread of the distribution.\n",
    "\n",
    "The shape of the normal distribution is determined by these two parameters. The mean determines where the distribution is centered, and the standard deviation determines how spread out the distribution is. If the standard deviation is small, then the distribution will be narrow and concentrated around the mean. If the standard deviation is large, then the distribution will be wider and more spread out.\n",
    "\n",
    "The normal distribution is symmetric, with the mean as the point of symmetry. About 68% of the data falls within one standard deviation of the mean, 95% falls within two standard deviations, and 99.7% falls within three standard deviations.\n",
    "\n",
    "The normal distribution is also known as the Gaussian distribution or the bell curve because of its characteristic bell shape. It is an important distribution in statistics and probability theory due to its many properties and applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48af3b62-af2a-48be-b400-33ac9f640887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b622bf5-5a64-4335-8562-62c8a3420d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "Normal distribution, also known as the Gaussian distribution or bell curve, is an important probability distribution in statistics and probability theory. It is important for several reasons:\n",
    "\n",
    "Central Limit Theorem: The normal distribution is a fundamental concept in the Central Limit Theorem, which states that the sum of a large number of independent random variables tends to follow a normal distribution, regardless of the underlying distribution of the individual random variables. This theorem is widely used in many fields, including finance, engineering, and physics.\n",
    "\n",
    "Parameter Estimation: Many statistical tests and models assume that the underlying distribution is normal. This makes it easier to estimate the parameters of the distribution and to perform statistical inference.\n",
    "\n",
    "Prediction: The normal distribution is often used to model errors and noise in data. This can be useful for making predictions and forecasting future trends.\n",
    "\n",
    "Here are a few real-life examples of normal distribution:\n",
    "\n",
    "Heights of people: The heights of people in a population tend to follow a normal distribution. The mean height and standard deviation can be used to describe the distribution of heights in a given population.\n",
    "\n",
    "Test scores: The scores on a standardized test tend to follow a normal distribution. This allows us to compare the performance of different groups of students and to set pass/fail cutoffs based on the distribution of scores.\n",
    "\n",
    "Errors in measurement: The errors in measurement when taking a large number of measurements tend to follow a normal distribution. This can be useful for determining the precision and accuracy of a measurement instrument.\n",
    "\n",
    "Stock market returns: The daily returns on stocks tend to follow a normal distribution. This can be useful for modeling and predicting stock market trends.\n",
    "\n",
    "Reaction times: The time it takes for a person to react to a stimulus tends to follow a normal distribution. This can be useful for studying cognitive processes and human behavior.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4f90bc-1ba3-4cbc-8933-67780be9602a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f066264-baa3-4f5f-a896-4cd34296db12",
   "metadata": {},
   "outputs": [],
   "source": [
    "The Bernoulli distribution is a discrete probability distribution that represents the outcome of a single binary experiment. In other words, it models the probability of a single event that can have only two possible outcomes, usually denoted as 1 or 0, success or failure, or true or false.\n",
    "\n",
    "For example, flipping a coin is a classic example of a Bernoulli trial. If we define \"heads\" as a success, then the probability of success (getting a heads) is p, and the probability of failure (getting a tails) is 1-p.\n",
    "\n",
    "The probability mass function (PMF) of the Bernoulli distribution can be expressed as:\n",
    "\n",
    "P(X=k) = p^k(1-p)^(1-k) for k=0,1\n",
    "\n",
    "where X is a random variable representing the outcome of the experiment, p is the probability of success, and k=0 or 1.\n",
    "\n",
    "The Binomial distribution, on the other hand, models the number of successes in a fixed number of independent Bernoulli trials. For example, if we flip a coin n times and count the number of heads, then the number of heads is a Binomial random variable.\n",
    "\n",
    "The probability mass function of the Binomial distribution can be expressed as:\n",
    "\n",
    "P(X=k) = (n choose k) * p^k * (1-p)^(n-k) for k=0,1,...,n\n",
    "\n",
    "where X is the random variable representing the number of successes in n trials, p is the probability of success in each trial, and (n choose k) is the binomial coefficient, which represents the number of ways to choose k successes out of n trials.\n",
    "\n",
    "The main difference between the Bernoulli and Binomial distributions is that the Bernoulli distribution models the probability of a single event, while the Binomial distribution models the number of successes in a fixed number of independent Bernoulli trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daa7443-5cda-4927-be31-7ec4ff69b970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b48ff6b-d9f5-4a28-88e8-1eb2be89068e",
   "metadata": {},
   "outputs": [],
   "source": [
    "We can use the standard normal distribution to solve this problem by transforming the original distribution to a standard normal distribution with mean 0 and standard deviation 1.\n",
    "\n",
    "To do this, we first calculate the z-score for the value x=60:\n",
    "\n",
    "z = (x - μ) / σ = (60 - 50) / 10 = 1\n",
    "\n",
    "where μ is the mean of the dataset and σ is the standard deviation.\n",
    "\n",
    "Next, we use a standard normal distribution table or calculator to find the probability that a randomly selected observation will be greater than 60, which is equivalent to finding the area under the standard normal distribution curve to the right of z=1:\n",
    "\n",
    "P(Z > 1) = 0.1587\n",
    "\n",
    "Therefore, the probability that a randomly selected observation from the given dataset will be greater than 60 is approximately 0.1587 or 15.87%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7adc82-3db4-4cc4-963a-ea09b8dcae2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e127e5d7-f2da-427a-99a1-86d09314b584",
   "metadata": {},
   "outputs": [],
   "source": [
    "The uniform distribution is a continuous probability distribution that models random variables that are equally likely to take on any value within a given interval. This means that the probability density function (PDF) is constant within the interval and zero outside of it.\n",
    "\n",
    "For example, if we roll a fair six-sided die, then each outcome has an equal probability of 1/6. We can model this as a discrete uniform distribution, where the random variable X takes on values {1,2,3,4,5,6} with equal probability. The probability mass function (PMF) of the discrete uniform distribution is:\n",
    "\n",
    "P(X=k) = 1/6 for k=1,2,3,4,5,6\n",
    "\n",
    "Similarly, if we have a continuous uniform distribution over the interval [a,b], then any value within that interval is equally likely to occur. The PDF of the continuous uniform distribution is:\n",
    "\n",
    "f(x) = 1 / (b-a) for a <= x <= b\n",
    "\n",
    "For example, if we have a uniform distribution of heights between 5 feet and 6 feet, then the PDF of the distribution is:\n",
    "\n",
    "f(x) = 1 / (6-5) = 1 for 5 <= x <= 6\n",
    "\n",
    "This means that the probability of selecting a person with height between 5 feet and 5.5 feet is the same as selecting a person with height between 5.5 feet and 6 feet, since both intervals have the same width and therefore the same probability density.\n",
    "\n",
    "The uniform distribution is commonly used in simulations and random number generation, where we want to generate random numbers that are uniformly distributed within a certain range. It is also used in some statistical tests, such as the Kolmogorov-Smirnov test for goodness-of-fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8234f20-47d3-4d4a-87c8-4acec5bd2467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29940410-c71a-4237-8e38-21b947b37daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "The z-score, also known as the standard score, is a dimensionless quantity that measures the number of standard deviations an observation is above or below the mean of a distribution. It is used to standardize a normal distribution, which has a mean of 0 and a standard deviation of 1, so that any value can be transformed into a standard normal variable with a known probability.\n",
    "\n",
    "The formula for calculating the z-score for an observation x from a normal distribution with mean μ and standard deviation σ is:\n",
    "\n",
    "z = (x - μ) / σ\n",
    "\n",
    "The z-score represents the distance between an observation and the mean of the distribution in terms of the number of standard deviations. A positive z-score indicates that the observation is above the mean, while a negative z-score indicates that it is below the mean.\n",
    "\n",
    "The importance of the z-score lies in its ability to standardize any normal distribution, regardless of the mean and standard deviation. This allows us to compare observations from different normal distributions and make meaningful inferences about their relative positions within their respective distributions. For example, we can use the z-score to determine the probability of observing a value as extreme as or more extreme than a given value in a normal distribution, or to compare the performance of individuals or groups on a standardized test.\n",
    "\n",
    "The z-score is also commonly used in statistical analysis, such as hypothesis testing and confidence interval estimation, where it helps to calculate the significance level and the confidence level of the results. It is an essential concept in statistics and provides a standardized way to interpret and compare data from normal distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8f19cc-d4c1-4c1f-8d9a-664097121152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6a4875-3626-4ab3-b30c-752ddd29cfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "The Central Limit Theorem (CLT) is a fundamental concept in statistics that states that as the sample size increases, the sampling distribution of the mean of a random variable approaches a normal distribution, regardless of the shape of the original population distribution. In other words, if we take multiple samples of size n from a population and calculate the mean of each sample, then the distribution of sample means will be approximately normal, with a mean equal to the population mean and a standard deviation equal to the population standard deviation divided by the square root of n.\n",
    "\n",
    "The significance of the Central Limit Theorem is that it allows us to make statistical inferences about population parameters based on sample statistics, even when the population distribution is unknown or non-normal. This is because the normal distribution is well-understood and can be used to calculate probabilities and confidence intervals. For example, if we are interested in estimating the population mean based on a sample mean, we can use the CLT to calculate the standard error of the mean and construct a confidence interval that contains the population mean with a certain level of confidence.\n",
    "\n",
    "The CLT is also important in hypothesis testing, where it allows us to use the normal distribution to calculate test statistics and p-values, and in quality control, where it can be used to monitor the mean and variability of a process over time. In addition, it is used in various fields such as finance, engineering, and physics, where the normal distribution is often used as a model for random variables.\n",
    "\n",
    "Overall, the Central Limit Theorem is a powerful tool in statistics that allows us to make meaningful inferences about population parameters based on sample statistics, and enables us to use the normal distribution as a powerful tool for analysis and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adea5d14-d9d9-496e-be32-6966e5fef94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c29dc8-a6df-4148-b83a-b84aec7bb922",
   "metadata": {},
   "outputs": [],
   "source": [
    "The Central Limit Theorem (CLT) is a powerful concept in statistics, but it is based on certain assumptions that must be met in order for it to apply. These assumptions are:\n",
    "\n",
    "Random Sampling: The samples must be chosen randomly from the population, with each observation having an equal chance of being selected.\n",
    "\n",
    "Independent Observations: The observations within each sample must be independent of each other. This means that the value of one observation does not depend on the value of another observation.\n",
    "\n",
    "Finite Population or Large Sample Size: The population from which the samples are drawn must be finite, or the sample size must be sufficiently large. A commonly used rule of thumb is that the sample size should be greater than or equal to 30.\n",
    "\n",
    "Population Distribution: The population distribution must have a finite mean and a finite standard deviation. The shape of the distribution can be any, but the distribution should not be too skewed or too heavy-tailed.\n",
    "\n",
    "If these assumptions are met, then the Central Limit Theorem can be applied to estimate population parameters based on sample statistics. However, if the assumptions are not met, then alternative methods such as non-parametric methods may need to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9872a1-c251-4bc9-b013-a4abe88f453f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
