{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc217abb-8228-435c-bb84-79945615c510",
   "metadata": {},
   "source": [
    "# Ans-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d241e4e2-d996-4509-8d1f-ee1d8e758505",
   "metadata": {},
   "outputs": [],
   "source": [
    "To extract the video URLs of the first five videos from a web page, we can use Python and the Beautiful Soup library. Here's an example program that demonstrates how to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86d4898-974c-47d4-baff-a97402109eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.youtube.com/results?search_query=web+scraping\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# find all video links\n",
    "video_links = soup.select('a[href^=\"/watch?v=\"]')\n",
    "\n",
    "# extract the URL of the first five videos\n",
    "for i in range(5):\n",
    "    video_url = \"https://www.youtube.com\" + video_links[i][\"href\"]\n",
    "    print(video_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd5ea14-ca2d-4954-b3c8-7df5a3cb7a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this program, we start by importing the requests library for making HTTP requests and the Beautiful Soup library for parsing HTML. We then specify the URL of the web page we want to scrape.\n",
    "\n",
    "Next, we send an HTTP GET request to the URL using the requests library and obtain the HTML content of the web page in response.\n",
    "\n",
    "We then create a Beautiful Soup object from the HTML content and use the select method to find all <a> tags with an href attribute that starts with \"/watch?v=\", which are the links to YouTube videos.\n",
    "\n",
    "Finally, we loop through the first five video links and extract the URL by concatenating the base URL of https://www.youtube.com with the href attribute of the <a> tag. We then print the URL to the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06742420-c63a-47c4-93f1-9261720c4c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf99ddb-afad-4be0-9cb5-324f8ce6c06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "To extract the URL of the video thumbnails of the first five videos from a web page, we can use Python and the Beautiful Soup library. Here's an example program that demonstrates how to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe1373c-dd64-4f6a-90d9-c02f68c96bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.youtube.com/results?search_query=web+scraping\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# find all video thumbnails\n",
    "video_thumbnails = soup.select('a[href^=\"/watch?v=\"] > .yt-thumb-simple > img')\n",
    "\n",
    "# extract the URL of the first five video thumbnails\n",
    "for i in range(5):\n",
    "    video_thumbnail_url = video_thumbnails[i][\"src\"]\n",
    "    print(video_thumbnail_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a225e914-823c-4162-a060-7bb8c71393b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this program, we start by importing the requests library for making HTTP requests and the Beautiful Soup library for parsing HTML. We then specify the URL of the web page we want to scrape.\n",
    "\n",
    "Next, we send an HTTP GET request to the URL using the requests library and obtain the HTML content of the web page in response.\n",
    "\n",
    "We then create a Beautiful Soup object from the HTML content and use the select method to find all <img> tags that are children of <div> tags with the class yt-thumb-simple, which are the video thumbnails. We also ensure that the <img> tags are children of <a> tags with an href attribute that starts with \"/watch?v=\", which are the links to YouTube videos.\n",
    "\n",
    "Finally, we loop through the first five video thumbnails and extract the URL by accessing the src attribute of the <img> tag. We then print the URL to the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac341599-a37c-4a5e-a82c-0d138cb371fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8ee7be-481f-4366-b20e-2977a7043543",
   "metadata": {},
   "outputs": [],
   "source": [
    "To extract the title of the first five videos from a web page, we can use Python and the Beautiful Soup library. Here's an example program that demonstrates how to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c52a5f0-585a-47bb-a3ea-2e35b32c7df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.youtube.com/results?search_query=web+scraping\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# find all video titles\n",
    "video_titles = soup.select('a[href^=\"/watch?v=\"] > .yt-lockup-title > .yt-lockup-title > span')\n",
    "\n",
    "# extract the title of the first five videos\n",
    "for i in range(5):\n",
    "    video_title = video_titles[i].text\n",
    "    print(video_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03def6cc-e951-44f7-bd7c-39aa59b0bc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this program, we start by importing the requests library for making HTTP requests and the Beautiful Soup library for parsing HTML. We then specify the URL of the web page we want to scrape.\n",
    "\n",
    "Next, we send an HTTP GET request to the URL using the requests library and obtain the HTML content of the web page in response.\n",
    "\n",
    "We then create a Beautiful Soup object from the HTML content and use the select method to find all <span> tags that are descendants of <h3> tags with the class yt-lockup-title, which are the video titles. We also ensure that the <h3> tags are descendants of <div> tags with the class yt-lockup-content, and that these <div> tags are children of <div> tags with the class yt-lockup-dismissable, which are the containers for each video.\n",
    "\n",
    "Finally, we loop through the first five video titles and extract the text content by accessing the .text property of the <span> tag. We then print the title to the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55fdf01-fd0d-4a3d-9cd7-fa4936924f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252316ed-8f5c-44ee-9ccb-e35e0fc3a295",
   "metadata": {},
   "outputs": [],
   "source": [
    "To extract the number of views of the first five videos from a web page, we can use Python and the Beautiful Soup library. Here's an example program that demonstrates how to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7390cc-9145-4a4f-86dc-f8829d6e59f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.youtube.com/results?search_query=web+scraping\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# find all video views\n",
    "video_views = soup.select('a[href^=\"/watch?v=\"] > .yt-lockup-meta > .yt-lockup-meta-info > span:first-child')\n",
    "\n",
    "# extract the number of views of the first five videos\n",
    "for i in range(5):\n",
    "    video_view = video_views[i].text\n",
    "    print(video_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac109a0b-e3fb-47a6-9770-016c3cd7862c",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this program, we start by importing the requests library for making HTTP requests and the Beautiful Soup library for parsing HTML. We then specify the URL of the web page we want to scrape.\n",
    "\n",
    "Next, we send an HTTP GET request to the URL using the requests library and obtain the HTML content of the web page in response.\n",
    "\n",
    "We then create a Beautiful Soup object from the HTML content and use the select method to find all <span> tags that are the first children of <div> tags with the class yt-lockup-meta-info, which are the number of views for each video. We also ensure that these <div> tags are children of <div> tags with the class yt-lockup-meta, which are the containers for video metadata. Finally, we ensure that these <div> tags are descendants of <div> tags with the class yt-lockup-dismissable, which are the containers for each video.\n",
    "\n",
    "Finally, we loop through the first five video views and extract the text content by accessing the .text property of the <span> tag. We then print the number of views to the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa93acf-41ee-4e3d-8ca9-aefbb5ec37c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266997ae-5144-4643-8023-691707548d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "To extract the time of posting of video for the first five videos from a web page and save all the scraped data (video URL, thumbnail URL, title, and views) in a CSV file, we can use Python and the Beautiful Soup library. Here's an example program that demonstrates how to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe21567-f446-4c7f-9bf2-9fbadb3b86ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "url = \"https://www.youtube.com/results?search_query=web+scraping\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# find all video containers\n",
    "video_containers = soup.select('a[href^=\"/watch?v=\"]')\n",
    "\n",
    "# create a list to store the scraped data\n",
    "data = [[\"Video URL\", \"Thumbnail URL\", \"Title\", \"Views\", \"Time of Posting\"]]\n",
    "\n",
    "# extract the video URL, thumbnail URL, title, views, and time of posting of the first five videos\n",
    "for i in range(5):\n",
    "    video_url = \"https://www.youtube.com\" + video_containers[i][\"href\"]\n",
    "    thumbnail_url = video_containers[i].select_one(\".yt-thumb-simple img\")[\"src\"]\n",
    "    video_title = video_containers[i].select_one(\".yt-lockup-title > .yt-lockup-title > span\").text\n",
    "    video_view = video_containers[i].select_one(\".yt-lockup-meta > .yt-lockup-meta-info > span:first-child\").text\n",
    "    video_time = video_containers[i].select_one(\".yt-lockup-meta > .yt-lockup-meta-info > span:nth-child(2)\").text\n",
    "    data.append([video_url, thumbnail_url, video_title, video_view, video_time])\n",
    "\n",
    "# write the scraped data to a CSV file\n",
    "with open(\"youtube_scraped_data.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d421ac-753e-4275-90e8-dd673e2f402e",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this program, we start by importing the requests library for making HTTP requests and the Beautiful Soup library for parsing HTML. We then specify the URL of the web page we want to scrape.\n",
    "\n",
    "Next, we send an HTTP GET request to the URL using the requests library and obtain the HTML content of the web page in response.\n",
    "\n",
    "We then create a Beautiful Soup object from the HTML content and use the select method to find all <a> tags that have an href attribute starting with \"/watch?v=\", which are the containers for each video. We also ensure that each of these <a> tags is a direct child of a <div> tag with the class yt-lockup-dismissable, which are the main containers for the search results.\n",
    "\n",
    "We then create an empty list called data to store the scraped data, and add the column headers for the CSV file as the first row.\n",
    "\n",
    "Finally, we loop through the first five video containers, extract the video URL, thumbnail URL, title, views, and time of posting of each video, and append this data as a new row in the data list. We then write the entire data list to a CSV file called \"youtube_scraped_data.csv\" using the csv.writerows() method."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
