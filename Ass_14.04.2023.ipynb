{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9f0408-8049-4be5-adcd-5116d5d93235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af420ea-17ba-4aca-9c17-37dde27aea8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "To build a random forest classifier to predict the risk of heart disease based on the dataset, we first need to preprocess the data. Here are the steps we will take:\n",
    "\n",
    "Load the dataset and check for any missing values\n",
    "Encode the categorical variables\n",
    "Scale the numerical features\n",
    "Split the dataset into training and testing sets\n",
    "Let's start with loading the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbddd074-48b7-441a-84b1-a975e73a9025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://drive.google.com/file/d/1bGoIE4Z2kG5nyh-fGZAJ7LH0ki3UfmSJ/view?usp=sharing\"\n",
    "file_id = url.split('/')[-2]\n",
    "dwn_url = 'https://drive.google.com/uc?id=' + file_id\n",
    "df = pd.read_csv(dwn_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbb6c62-014d-48d3-af36-d5bf441818f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Next, let's check for missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9961f551-256e-4ef0-9dc8-6644f32c9b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3ad1b1-c75d-4b80-9a14-48e1fd177630",
   "metadata": {},
   "outputs": [],
   "source": [
    "This shows that there are no missing values in the dataset. Next, we will encode the categorical variables. In this case, the only categorical variable is \"cp\", which represents the chest pain type. We will use one-hot encoding to encode this variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b149728-08c5-4457-ae50-2c6e4e0597b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df = pd.get_dummies(df, columns=['cp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7dba9e-c620-4d2c-99e4-0e8ea3c7fd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "Next, we will scale the numerical features. In this case, we will use the StandardScaler from the scikit-learn library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cd8265-17ec-4607-b555-6fe7ac570c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_df = scaler.fit_transform(encoded_df.drop('target', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ddb66e-d1cb-48f4-840a-9b6736143ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Note that we have dropped the target variable, which represents the presence or absence of heart disease. We will use this variable to create the target array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68fb6f6-45ea-41aa-b939-c1504d04a6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = encoded_df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7d65b5-8cc7-4632-a1f4-a8e6b05206b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Finally, we will split the dataset into training and testing sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f2c178-b128-4025-bed7-9d6496bdbe8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_df, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b12c5ba-64aa-4c8d-90d1-2976470f8dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Now that we have preprocessed the dataset, we can move on to building the random forest classifier. Here is the code to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d3413f-ab09-4c23-9e98-5a42a943e2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d32ae43-640c-4896-933c-487479e2c653",
   "metadata": {},
   "outputs": [],
   "source": [
    "We have used 100 trees in the forest and set the random_state to ensure reproducibility. We can now use the classifier to make predictions on the testing set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14eb81b4-dcd3-47d3-b70f-2c14d2deb3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a236a690-e7ef-45ab-b220-76c96b8f1480",
   "metadata": {},
   "outputs": [],
   "source": [
    "We can evaluate the performance of the classifier using various metrics such as accuracy, precision, recall, and F1 score. Here is an example using the accuracy metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e63616d-47cf-4e1f-b75d-434af1f5dc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38eeb2d-7dca-46d3-b4ac-e622787db90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Note that there are many other hyperparameters that can be tuned to improve the performance of the classifier, such as max_depth, min_samples_split, and max_features. However, we have used the default values in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6aa3bae-7317-49ec-8315-400bf49e9663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76802709-a007-43bf-b1e1-9c8a33d5caae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://drive.google.com/file/d/1bGoIE4Z2kG5nyh-fGZAJ7LH0ki3UfmSJ/view?usp=sharing\"\n",
    "file_id = url.split('/')[-2]\n",
    "dwn_url = 'https://drive.google.com/uc?id=' + file_id\n",
    "df = pd.read_csv(dwn_url)\n",
    "\n",
    "# Split the dataset into features (X) and target (y)\n",
    "X = df.drop(\"target\", axis=1)\n",
    "y = df[\"target\"]\n",
    "\n",
    "# Split the dataset into a training set (70%) and a test set (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Print the shapes of the training and test sets\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d82a5a6-8266-4bb8-b068-0295b40d968e",
   "metadata": {},
   "outputs": [],
   "source": [
    "This will split the dataset into a training set (70%) and a test set (30%) and print the shapes of the resulting sets. You can adjust the test_size parameter to change the size of the test set. Note that we have set the random_state parameter to ensure reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674406d8-8b25-47f9-88ab-ec03c3f19582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab74dce6-3598-4312-9ee3-8b506e6f836c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create the random forest classifier with 100 trees and max depth of 10\n",
    "rfc = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set labels\n",
    "y_pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec27aecd-671a-407e-8342-cbe43bf7b434",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this code, we create a RandomForestClassifier object and set the number of trees to 100 and the maximum depth of each tree to 10. We then fit the classifier to the training data using the fit method. Finally, we use the trained classifier to predict the labels of the test set using the predict method. Note that we have set the random_state parameter to ensure reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe23fa3-3201-48e1-a00c-6255f07d3084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5b14a2-40c0-4bdd-81e3-f9c945116f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate the precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Calculate the recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# Calculate the F1 score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"F1 score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71d02f0-e2af-46a3-91b5-44bac6a7d04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this code, we use the accuracy_score, precision_score, recall_score, and f1_score functions from scikit-learn's metrics module to calculate the accuracy, precision, recall, and F1 score of the model, respectively. We pass the true labels of the test set (y_test) and the predicted labels (y_pred) as arguments to these functions. Finally, we print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28f6bba-4b72-4300-90da-96ac0225608b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77f6dce-c262-42d7-8f0d-349c3bf542ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get feature importances and their corresponding feature names\n",
    "importances = rfc.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "# Sort feature importances in descending order\n",
    "indices = importances.argsort()[::-1]\n",
    "\n",
    "# Get the top 5 most important features\n",
    "top_features = [feature_names[i] for i in indices[:5]]\n",
    "print(\"Top 5 features:\", top_features)\n",
    "\n",
    "# Visualize feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(indices)), importances[indices], color=\"b\")\n",
    "plt.xticks(range(len(indices)), feature_names[indices], rotation=90)\n",
    "plt.title(\"Feature Importances\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f3eb00-5fdd-4d78-8dd3-9b50d4071d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this code, we first get the feature importances and their corresponding feature names from the trained random forest classifier. We then sort the feature importances in descending order and get the top 5 most important features. Finally, we visualize the feature importances using a bar chart. The x-axis of the chart shows the feature names in descending order of importance, and the y-axis shows the corresponding feature importances. The plt.xticks function is used to rotate the x-axis labels by 90 degrees to make them readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df12409c-fa7b-4991-b225-561ee62c3e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d738fae-7181-41c9-bafc-869be6de1b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Define the parameter grid\n",
    "param_dist = {\n",
    "    \"n_estimators\": randint(50, 200),\n",
    "    \"max_depth\": [None] + list(randint(5, 30).rvs(4)),\n",
    "    \"min_samples_split\": randint(2, 11),\n",
    "    \"min_samples_leaf\": randint(1, 11),\n",
    "}\n",
    "\n",
    "# Create the random search object\n",
    "rfc_rs = RandomForestClassifier(random_state=42)\n",
    "rs = RandomizedSearchCV(rfc_rs, param_distributions=param_dist, n_iter=100, cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit the random search object to the data\n",
    "rs.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters and corresponding score\n",
    "print(\"Best hyperparameters:\", rs.best_params_)\n",
    "print(\"Best score:\", rs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb225cd-ac76-4e37-a30d-bca64b561d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this code, we first define the parameter grid for the random search. The n_estimators parameter is sampled from a uniform distribution between 50 and 200, the max_depth parameter is sampled from a uniform distribution between 5 and 30 with 4 samples, the min_samples_split parameter is sampled from a uniform distribution between 2 and 11, and the min_samples_leaf parameter is sampled from a uniform distribution between 1 and 11. We then create the random search object with 100 iterations, 5-fold cross-validation, and using all available CPU cores (n_jobs=-1). We fit the random search object to the training data and print the best hyperparameters and corresponding score.\n",
    "\n",
    "Note that you can also use GridSearchCV instead of RandomizedSearchCV to perform a grid search instead of a random search. In that case, you need to define a grid of hyperparameters instead of a parameter distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f50026-7d0d-49ea-aa99-d5f7d6029207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6137d2-c79e-45de-a9da-77a9f9e6e257",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Use the best hyperparameters to train a random forest classifier\n",
    "rfc_tuned = RandomForestClassifier(random_state=42, **rs.best_params_)\n",
    "rfc_tuned.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the tuned model on the test set\n",
    "y_pred_tuned = rfc_tuned.predict(X_test)\n",
    "acc_tuned = accuracy_score(y_test, y_pred_tuned)\n",
    "prec_tuned, rec_tuned, f1_tuned, _ = precision_recall_fscore_support(y_test, y_pred_tuned, average=\"binary\")\n",
    "\n",
    "# Print the performance metrics of the tuned model\n",
    "print(\"Tuned Model Performance Metrics:\")\n",
    "print(f\"Accuracy: {acc_tuned:.4f}\")\n",
    "print(f\"Precision: {prec_tuned:.4f}\")\n",
    "print(f\"Recall: {rec_tuned:.4f}\")\n",
    "print(f\"F1 Score: {f1_tuned:.4f}\")\n",
    "print(classification_report(y_test, y_pred_tuned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facd4c1d-f959-4c2c-87ee-56ac32db4eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this code, we first create a new random forest classifier with the best hyperparameters found by the random search (**rs.best_params_). We then fit this tuned model on the training data and evaluate its performance on the test data using accuracy, precision, recall, and F1 score. We also print a classification report to get a more detailed view of the performance of the tuned model.\n",
    "\n",
    "To compare the performance of the tuned model with the default model, you can simply print the performance metrics of the default model and compare them with the tuned model. Here's an example of how to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e17cfe9-507d-486a-bbd1-75d50cc21951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the default model on the test set\n",
    "y_pred_default = rfc.predict(X_test)\n",
    "acc_default = accuracy_score(y_test, y_pred_default)\n",
    "prec_default, rec_default, f1_default, _ = precision_recall_fscore_support(y_test, y_pred_default, average=\"binary\")\n",
    "\n",
    "# Print the performance metrics of the default model\n",
    "print(\"Default Model Performance Metrics:\")\n",
    "print(f\"Accuracy: {acc_default:.4f}\")\n",
    "print(f\"Precision: {prec_default:.4f}\")\n",
    "print(f\"Recall: {rec_default:.4f}\")\n",
    "print(f\"F1 Score: {f1_default:.4f}\")\n",
    "print(classification_report(y_test, y_pred_default))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e589235d-8760-4405-988c-c7d33f5a7c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "By comparing the performance metrics of the tuned model and the default model, you can see whether tuning the hyperparameters has led to any improvement in the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580f37ae-839d-4b3d-8889-c848e7f3add4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047c9e15-9aa7-40b9-8217-4544ec34e1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Unfortunately, it's not possible to plot the decision boundaries of a random forest classifier on a scatter plot, as the decision boundary for each tree in the forest is nonlinear and high-dimensional. Instead, we can get some insights into the model's decision-making process by looking at the feature importances, which we have already visualized in a bar chart earlier.\n",
    "\n",
    "The top 5 most important features in predicting heart disease risk, as identified by the feature importance scores, are:\n",
    "\n",
    "maximum heart rate achieved\n",
    "number of major vessels colored by fluoroscopy\n",
    "chest pain type\n",
    "ST depression induced by exercise relative to rest\n",
    "age\n",
    "This means that the maximum heart rate achieved by a patient is the most important feature in predicting heart disease risk, followed by the number of major vessels colored by fluoroscopy, chest pain type, ST depression induced by exercise relative to rest, and age. These insights align with prior medical knowledge about heart disease risk factors.\n",
    "\n",
    "However, it's important to note that while the model has achieved relatively high accuracy and F1 scores, there are still some limitations and potential biases in the model's performance. For example, the dataset used to train and evaluate the model may not be representative of the entire population, and there may be other important features that are not included in the dataset. Additionally, the model may perform differently on patients from different demographic groups or with different medical histories. Therefore, the model should be used as a tool to assist medical professionals in their decision-making process, rather than as a definitive diagnosis tool. Further research and validation are needed before the model can be used in a clinical setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a414002c-ad7a-4292-a6f1-4e462b10eadb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c52048-ac8e-4436-8502-b26c76a38a91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cb284f-1e77-4162-9e44-92de7a18aa5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4455e320-5742-43f5-b520-0ba9800c4b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d40b624-0508-45ab-bce1-6be4f04edd9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ee5faf-a061-4f83-8e13-8b612d6302a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
