{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b6dac9-dcac-4e4e-977a-9f0c7791029d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e7beed-136c-4004-a85a-6380e7c37240",
   "metadata": {},
   "outputs": [],
   "source": [
    "The purpose of forward propagation in a neural network is to process input data and generate an output prediction. It is the first step in the typical training and inference process of a neural network.\n",
    "\n",
    "During forward propagation, the neural network takes the input data (features or raw data) and processes it through a series of interconnected layers, also known as neurons. Each neuron in a layer is associated with weights and biases, and the information from the previous layer is combined with these weights and biases to produce an output value for each neuron in the current layer.\n",
    "\n",
    "The process of forward propagation can be summarized as follows:\n",
    "\n",
    "Input Layer: The input data is passed to the input layer of the neural network. Each neuron in the input layer represents one feature of the input data.\n",
    "\n",
    "Hidden Layers: The input data then flows through one or more hidden layers. Each neuron in these layers performs a weighted sum of the outputs from the previous layer and applies an activation function to introduce non-linearity.\n",
    "\n",
    "Output Layer: Finally, the processed data propagates through the output layer, where the neurons produce the final output prediction of the neural network. The number of neurons in the output layer depends on the type of problem being solved. For example, in binary classification, there will be one neuron, while for multi-class classification, there will be multiple neurons, each representing a different class.\n",
    "\n",
    "The purpose of this forward pass is to compute the output of the neural network given the input data and the current set of weights and biases. During training, the output of the forward propagation is compared to the actual target labels, and an appropriate loss function is used to measure the difference between the predicted output and the true labels. This loss is then used in the subsequent step of backpropagation to update the weights and biases of the neural network, ultimately improving its performance over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd66b77d-a0bb-46e7-a53d-f88087d23b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0a2bc9-2361-40c0-8b48-8188789a6338",
   "metadata": {},
   "outputs": [],
   "source": [
    "In a single-layer feedforward neural network (also known as a perceptron or a single-layer perceptron), there is only one layer of neurons, which is the output layer. This type of neural network is limited in its capability to solve complex problems and is mainly used for simple linearly separable tasks. Nonetheless, understanding its mathematical implementation can provide insights into the fundamentals of neural networks.\n",
    "\n",
    "Let's denote the following:\n",
    "\n",
    "Input data: \n",
    "�\n",
    "=\n",
    "[\n",
    "�\n",
    "1\n",
    ",\n",
    "�\n",
    "2\n",
    ",\n",
    ".\n",
    ".\n",
    ".\n",
    ",\n",
    "�\n",
    "�\n",
    "]\n",
    "X=[x \n",
    "1\n",
    "​\n",
    " ,x \n",
    "2\n",
    "​\n",
    " ,...,x \n",
    "n\n",
    "​\n",
    " ], where \n",
    "�\n",
    "n is the number of input features.\n",
    "Weights: \n",
    "�\n",
    "=\n",
    "[\n",
    "�\n",
    "1\n",
    ",\n",
    "�\n",
    "2\n",
    ",\n",
    ".\n",
    ".\n",
    ".\n",
    ",\n",
    "�\n",
    "�\n",
    "]\n",
    "W=[w \n",
    "1\n",
    "​\n",
    " ,w \n",
    "2\n",
    "​\n",
    " ,...,w \n",
    "n\n",
    "​\n",
    " ], where \n",
    "�\n",
    "�\n",
    "w \n",
    "i\n",
    "​\n",
    "  is the weight associated with the \n",
    "�\n",
    "i-th input feature.\n",
    "Biases: \n",
    "�\n",
    "b is the bias term.\n",
    "The forward propagation in a single-layer feedforward neural network is implemented mathematically as follows:\n",
    "\n",
    "Weighted Sum: Compute the weighted sum of the inputs and biases for each neuron in the output layer.\n",
    "�\n",
    "=\n",
    "∑\n",
    "�\n",
    "=\n",
    "1\n",
    "�\n",
    "(\n",
    "�\n",
    "�\n",
    "⋅\n",
    "�\n",
    "�\n",
    ")\n",
    "+\n",
    "�\n",
    "z= \n",
    "i=1\n",
    "∑\n",
    "n\n",
    "​\n",
    " (w \n",
    "i\n",
    "​\n",
    " ⋅x \n",
    "i\n",
    "​\n",
    " )+b\n",
    "Activation Function: Apply an activation function to the weighted sum. Common activation functions used in single-layer networks include the step function (binary output) or the sigmoid function (continuous output between 0 and 1).\n",
    "For binary output (Step function):\n",
    "\n",
    "output\n",
    "=\n",
    "{\n",
    "1\n",
    "if \n",
    "�\n",
    "≥\n",
    "0\n",
    "0\n",
    "otherwise\n",
    "output={ \n",
    "1\n",
    "0\n",
    "​\n",
    "  \n",
    "if z≥0\n",
    "otherwise\n",
    "​\n",
    " \n",
    "For continuous output (Sigmoid function):\n",
    "\n",
    "output\n",
    "=\n",
    "�\n",
    "(\n",
    "�\n",
    ")\n",
    "=\n",
    "1\n",
    "1\n",
    "+\n",
    "�\n",
    "−\n",
    "�\n",
    "output=σ(z)= \n",
    "1+e \n",
    "−z\n",
    " \n",
    "1\n",
    "​\n",
    " \n",
    "Final Output: The output of the activation function is the final output of the single-layer feedforward neural network.\n",
    "In summary, the single-layer feedforward neural network takes the input data, computes the weighted sum of the inputs and biases, applies an activation function, and produces the output prediction. Note that this type of network is limited to solving linearly separable problems, and for more complex tasks, deeper networks with multiple layers (multi-layer feedforward neural networks) are used. These deeper networks can learn non-linear representations and solve more intricate tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93342e2f-00d6-4d67-8000-ded1fd026e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903efd8f-97d0-45cc-bf60-58052364e3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Activation functions are an essential component of forward propagation in neural networks. They introduce non-linearity to the network, allowing it to learn complex patterns and relationships in the data. Without activation functions, the neural network would essentially be a linear model, regardless of its depth.\n",
    "\n",
    "During forward propagation, the activation function is applied to the output of each neuron in the hidden layers (and the output layer) after the weighted sum of inputs and biases is computed. The activation function determines whether a neuron should be activated (fire) or not based on the input it receives.\n",
    "\n",
    "Here's how activation functions are used during forward propagation:\n",
    "\n",
    "Weighted Sum: For each neuron, the forward propagation starts by computing the weighted sum of inputs and biases:\n",
    "\n",
    "�\n",
    "=\n",
    "∑\n",
    "�\n",
    "=\n",
    "1\n",
    "�\n",
    "(\n",
    "�\n",
    "�\n",
    "⋅\n",
    "�\n",
    "�\n",
    ")\n",
    "+\n",
    "�\n",
    "z= \n",
    "i=1\n",
    "∑\n",
    "n\n",
    "​\n",
    " (w \n",
    "i\n",
    "​\n",
    " ⋅x \n",
    "i\n",
    "​\n",
    " )+b\n",
    "where \n",
    "�\n",
    "�\n",
    "x \n",
    "i\n",
    "​\n",
    "  is the \n",
    "�\n",
    "i-th input feature, \n",
    "�\n",
    "�\n",
    "w \n",
    "i\n",
    "​\n",
    "  is the weight associated with the \n",
    "�\n",
    "i-th input feature, and \n",
    "�\n",
    "b is the bias term.\n",
    "\n",
    "Activation Function: Once the weighted sum is calculated, it is passed through the activation function, which introduces non-linearity to the output. The choice of activation function depends on the problem and the network architecture. Some commonly used activation functions are:\n",
    "\n",
    "Sigmoid function: \n",
    "�\n",
    "(\n",
    "�\n",
    ")\n",
    "=\n",
    "1\n",
    "1\n",
    "+\n",
    "�\n",
    "−\n",
    "�\n",
    "σ(z)= \n",
    "1+e \n",
    "−z\n",
    " \n",
    "1\n",
    "​\n",
    " \n",
    "Hyperbolic tangent (tanh) function: \n",
    "tanh\n",
    "⁡\n",
    "(\n",
    "�\n",
    ")\n",
    "=\n",
    "�\n",
    "�\n",
    "−\n",
    "�\n",
    "−\n",
    "�\n",
    "�\n",
    "�\n",
    "+\n",
    "�\n",
    "−\n",
    "�\n",
    "tanh(z)= \n",
    "e \n",
    "z\n",
    " +e \n",
    "−z\n",
    " \n",
    "e \n",
    "z\n",
    " −e \n",
    "−z\n",
    " \n",
    "​\n",
    " \n",
    "Rectified Linear Unit (ReLU): \n",
    "�\n",
    "(\n",
    "�\n",
    ")\n",
    "=\n",
    "max\n",
    "⁡\n",
    "(\n",
    "0\n",
    ",\n",
    "�\n",
    ")\n",
    "f(z)=max(0,z)\n",
    "Leaky ReLU: \n",
    "�\n",
    "(\n",
    "�\n",
    ")\n",
    "=\n",
    "max\n",
    "⁡\n",
    "(\n",
    "�\n",
    "�\n",
    ",\n",
    "�\n",
    ")\n",
    "f(z)=max(αz,z), where \n",
    "�\n",
    "α is a small positive constant (typically a small value like 0.01)\n",
    "Parametric ReLU (PReLU): \n",
    "�\n",
    "(\n",
    "�\n",
    ")\n",
    "=\n",
    "max\n",
    "⁡\n",
    "(\n",
    "�\n",
    "�\n",
    ",\n",
    "�\n",
    ")\n",
    "f(z)=max(αz,z), where \n",
    "�\n",
    "α is a learnable parameter\n",
    "Softmax function (used in the output layer for multi-class classification): \n",
    "softmax\n",
    "(\n",
    "�\n",
    "�\n",
    ")\n",
    "=\n",
    "�\n",
    "�\n",
    "�\n",
    "∑\n",
    "�\n",
    "=\n",
    "1\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "softmax(z \n",
    "i\n",
    "​\n",
    " )= \n",
    "∑ \n",
    "j=1\n",
    "K\n",
    "​\n",
    " e \n",
    "z \n",
    "j\n",
    "​\n",
    " \n",
    " \n",
    "e \n",
    "z \n",
    "i\n",
    "​\n",
    " \n",
    " \n",
    "​\n",
    "  for \n",
    "�\n",
    "=\n",
    "1\n",
    ",\n",
    "2\n",
    ",\n",
    ".\n",
    ".\n",
    ".\n",
    ",\n",
    "�\n",
    "i=1,2,...,K, where \n",
    "�\n",
    "K is the number of classes.\n",
    "Output: The output of the activation function becomes the output of the neuron, which is then passed to the next layer (in the case of hidden layers) or becomes the final output of the neural network (in the case of the output layer).\n",
    "\n",
    "By introducing non-linearity through activation functions, neural networks can model complex relationships and make them powerful tools for various tasks, such as classification, regression, language processing, and more. Different activation functions have different characteristics and can affect the network's learning capabilities and convergence during training. Therefore, choosing an appropriate activation function is an important design decision in building a neural network architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4facf5-cc59-4276-aaec-12e950aa8b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057bd1dc-55a1-48de-a24c-76c5c939208a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Weights and biases play a critical role in forward propagation within a neural network. They are the learnable parameters that the network updates during the training process to make accurate predictions and solve a given task effectively.\n",
    "\n",
    "Here's the role of weights and biases during forward propagation:\n",
    "\n",
    "Weights:\n",
    "\n",
    "Weights are the parameters associated with the connections between neurons in different layers of the neural network.\n",
    "Each connection between two neurons has an associated weight, which determines the strength or importance of that connection.\n",
    "During forward propagation, the input data is multiplied element-wise with the corresponding weights, and the weighted sum is computed.\n",
    "These weights control how much each input feature influences the neuron's output and are crucial for learning the patterns and relationships in the data.\n",
    "Biases:\n",
    "\n",
    "Biases are additional learnable parameters in a neural network that are used to shift the output of a neuron.\n",
    "Each neuron has one associated bias term, which is independent of the input data.\n",
    "Biases allow the neural network to model situations where the output may not be zero when all input values are zero.\n",
    "During forward propagation, the biases are added to the weighted sum of inputs to introduce translation or shifting of the output space.\n",
    "The forward propagation process can be summarized as follows, incorporating weights and biases:\n",
    "\n",
    "Weighted Sum: For each neuron, the input data is multiplied element-wise with the corresponding weights. The weighted sum of inputs and biases is computed as:\n",
    "\n",
    "�\n",
    "=\n",
    "∑\n",
    "�\n",
    "=\n",
    "1\n",
    "�\n",
    "(\n",
    "�\n",
    "�\n",
    "⋅\n",
    "�\n",
    "�\n",
    ")\n",
    "+\n",
    "�\n",
    "z= \n",
    "i=1\n",
    "∑\n",
    "n\n",
    "​\n",
    " (w \n",
    "i\n",
    "​\n",
    " ⋅x \n",
    "i\n",
    "​\n",
    " )+b\n",
    "where \n",
    "�\n",
    "�\n",
    "x \n",
    "i\n",
    "​\n",
    "  is the \n",
    "�\n",
    "i-th input feature, \n",
    "�\n",
    "�\n",
    "w \n",
    "i\n",
    "​\n",
    "  is the weight associated with the \n",
    "�\n",
    "i-th input feature, and \n",
    "�\n",
    "b is the bias term.\n",
    "\n",
    "Activation Function: The weighted sum is then passed through an activation function to introduce non-linearity and produce the output of the neuron.\n",
    "\n",
    "Output: The output of the activation function becomes the output of the neuron, which is either passed to the next layer (in the case of hidden layers) or becomes the final output of the neural network (in the case of the output layer).\n",
    "\n",
    "The process of forward propagation, including the use of weights and biases, allows the neural network to map input data to output predictions and is the first step in the training and inference process of a neural network. During training, the network updates the weights and biases through backpropagation to minimize the difference between the predicted output and the true labels, ultimately improving its performance on the task at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc14783f-a942-4980-ae5d-90c59d2b5be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18aafa6e-c084-4934-8646-a24c8ec6a2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "The purpose of applying a softmax function in the output layer during forward propagation is to convert the raw output scores (also known as logits) of a neural network into a probability distribution over multiple classes.\n",
    "\n",
    "In many classification problems, neural networks are required to assign input data to one of several possible classes (multi-class classification). The output layer of the neural network typically has as many neurons as there are classes in the problem. Each neuron in the output layer represents a class and produces a score (logit) that indicates how likely the input belongs to that class.\n",
    "\n",
    "However, these raw scores (logits) do not directly represent probabilities and may not sum up to 1. The softmax function is used to convert these scores into a valid probability distribution by ensuring that they are non-negative and sum up to 1. This is achieved through the following formula for the softmax function:\n",
    "\n",
    "softmax\n",
    "(\n",
    "�\n",
    "�\n",
    ")\n",
    "=\n",
    "�\n",
    "�\n",
    "�\n",
    "∑\n",
    "�\n",
    "=\n",
    "1\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "softmax(z \n",
    "i\n",
    "​\n",
    " )= \n",
    "∑ \n",
    "j=1\n",
    "K\n",
    "​\n",
    " e \n",
    "z \n",
    "j\n",
    "​\n",
    " \n",
    " \n",
    "e \n",
    "z \n",
    "i\n",
    "​\n",
    " \n",
    " \n",
    "​\n",
    " \n",
    "where \n",
    "�\n",
    "�\n",
    "z \n",
    "i\n",
    "​\n",
    "  is the raw score (logit) of the \n",
    "�\n",
    "i-th class, \n",
    "�\n",
    "K is the total number of classes, and \n",
    "�\n",
    "e is the base of the natural logarithm (Euler's number).\n",
    "\n",
    "The softmax function exponentiates the raw scores, making them positive, and then normalizes them by dividing each exponentiated score by the sum of all exponentiated scores. This normalization process ensures that the resulting values represent probabilities.\n",
    "\n",
    "The benefits of using the softmax function in the output layer include:\n",
    "\n",
    "Probability Interpretation: The softmax output can be interpreted as the estimated probability that the input belongs to each class. Each value represents the likelihood of the input being classified into the corresponding class.\n",
    "\n",
    "Classification Decision: During inference or testing, the class with the highest softmax probability is chosen as the predicted class for the input.\n",
    "\n",
    "Loss Calculation: The softmax function is often used in conjunction with the cross-entropy loss function, which measures the difference between the predicted probabilities and the true labels. This loss is commonly used in multi-class classification tasks and is essential for training the neural network effectively.\n",
    "\n",
    "In summary, applying the softmax function in the output layer is crucial for obtaining valid probabilities for multi-class classification problems and facilitates the correct interpretation and use of the neural network's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97968e2e-efed-45e7-93c2-6cf4fa65bb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5186801-39c2-4a6a-b82b-e6112805781c",
   "metadata": {},
   "outputs": [],
   "source": [
    "The purpose of backward propagation, also known as backpropagation, in a neural network is to update the model's parameters (weights and biases) to minimize the difference between the predicted output and the actual target labels. It is the key algorithm used for training neural networks and plays a fundamental role in optimizing the model's performance on a given task.\n",
    "\n",
    "Backward propagation is the process by which the neural network's error (also known as loss) is propagated backward from the output layer to the input layer, and the gradients of the model's parameters with respect to the loss are computed. These gradients indicate the direction and magnitude of the change needed for each parameter to reduce the overall error.\n",
    "\n",
    "Here's how backward propagation works in a nutshell:\n",
    "\n",
    "Forward Propagation: During the forward propagation phase, the input data is fed through the neural network, and the output is computed. Each layer's neurons perform a weighted sum of inputs and biases, followed by an activation function, to produce the output.\n",
    "\n",
    "Loss Calculation: After forward propagation, the output of the neural network is compared to the true target labels, and a loss function is used to quantify the difference between the predicted output and the actual labels. Common loss functions include mean squared error (MSE) for regression tasks and cross-entropy loss for classification tasks.\n",
    "\n",
    "Backward Propagation: The gradients of the loss with respect to the model's parameters (weights and biases) are calculated using the chain rule of calculus. The gradients represent the sensitivity of the loss to changes in each parameter. The gradients are computed layer by layer, starting from the output layer and propagating backward to the input layer.\n",
    "\n",
    "Parameter Updates: Once the gradients are computed, they indicate the direction in which each parameter should be adjusted to reduce the loss. The parameters are then updated using optimization algorithms like stochastic gradient descent (SGD) or its variants (e.g., Adam, RMSprop) to minimize the loss.\n",
    "\n",
    "Iterative Process: Steps 1 to 4 are repeated multiple times (epochs) during the training process. Each iteration consists of forward propagation, loss calculation, backward propagation, and parameter updates. Over time, the model's parameters are adjusted to learn better representations and improve its ability to make accurate predictions on unseen data.\n",
    "\n",
    "By iteratively adjusting the model's parameters based on the gradients obtained from backward propagation, the neural network learns from the training data and generalizes to make predictions on new, unseen data. The backward propagation algorithm makes it possible for neural networks to learn complex patterns and relationships in the data and has been a crucial advancement in the field of deep learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240ddce7-63f1-4d21-ac84-3242264380f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8b63fb-a84b-45e3-aeef-5f020a99684c",
   "metadata": {},
   "outputs": [],
   "source": [
    "In a single-layer feedforward neural network (also known as a perceptron), backward propagation involves calculating the gradients of the model's parameters (weights and biases) with respect to the loss function. This process enables us to update the parameters to minimize the error and improve the model's performance. Let's go through the mathematical steps of backward propagation in a single-layer feedforward neural network:\n",
    "\n",
    "Weighted Sum and Activation:\n",
    "Recall the forward propagation step, where for a single neuron in the output layer, the weighted sum of inputs and biases is computed as:\n",
    "\n",
    "�\n",
    "=\n",
    "∑\n",
    "�\n",
    "=\n",
    "1\n",
    "�\n",
    "(\n",
    "�\n",
    "�\n",
    "⋅\n",
    "�\n",
    "�\n",
    ")\n",
    "+\n",
    "�\n",
    "z= \n",
    "i=1\n",
    "∑\n",
    "n\n",
    "​\n",
    " (w \n",
    "i\n",
    "​\n",
    " ⋅x \n",
    "i\n",
    "​\n",
    " )+b\n",
    "and then passed through an activation function (e.g., sigmoid or softmax) to obtain the output \n",
    "�\n",
    "a.\n",
    "\n",
    "Loss Function:\n",
    "Assume we have a training dataset with input data \n",
    "�\n",
    "X and corresponding target labels \n",
    "�\n",
    "Y. The loss function \n",
    "�\n",
    "L is used to quantify the difference between the predicted output \n",
    "�\n",
    "a and the true target labels \n",
    "�\n",
    "Y. For a single training example, the loss function could be the mean squared error (MSE) for regression or the cross-entropy loss for classification.\n",
    "\n",
    "Backward Propagation:\n",
    "The goal of backward propagation is to calculate the gradients of the loss function \n",
    "�\n",
    "L with respect to the model's parameters \n",
    "�\n",
    "W (weights) and \n",
    "�\n",
    "b (biases).\n",
    "\n",
    "a. Calculate the gradient of the loss with respect to the output of the neuron (\n",
    "∂\n",
    "�\n",
    "∂\n",
    "�\n",
    "∂a\n",
    "∂L\n",
    "​\n",
    " ):\n",
    "The specific form of this derivative depends on the chosen loss function. For example, for mean squared error (MSE) loss, it would be:\n",
    "\n",
    "∂\n",
    "�\n",
    "∂\n",
    "�\n",
    "=\n",
    "2\n",
    "(\n",
    "�\n",
    "−\n",
    "�\n",
    ")\n",
    "∂a\n",
    "∂L\n",
    "​\n",
    " =2(a−y)\n",
    "where \n",
    "�\n",
    "a is the predicted output of the neuron, and \n",
    "�\n",
    "y is the true target label.\n",
    "\n",
    "b. Calculate the gradient of the output of the neuron with respect to the weighted sum (\n",
    "∂\n",
    "�\n",
    "∂\n",
    "�\n",
    "∂z\n",
    "∂a\n",
    "​\n",
    " ):\n",
    "This is the derivative of the activation function with respect to the weighted sum. The specific form depends on the activation function used.\n",
    "\n",
    "c. Calculate the gradients of the loss with respect to the weights and biases:\n",
    "Using the chain rule of calculus, the gradients of the loss with respect to the weights (\n",
    "∂\n",
    "�\n",
    "∂\n",
    "�\n",
    "�\n",
    "∂w \n",
    "i\n",
    "​\n",
    " \n",
    "∂L\n",
    "​\n",
    " ) and biases (\n",
    "∂\n",
    "�\n",
    "∂\n",
    "�\n",
    "∂b\n",
    "∂L\n",
    "​\n",
    " ) can be expressed as follows:\n",
    "\n",
    "∂\n",
    "�\n",
    "∂\n",
    "�\n",
    "�\n",
    "=\n",
    "∂\n",
    "�\n",
    "∂\n",
    "�\n",
    "⋅\n",
    "∂\n",
    "�\n",
    "∂\n",
    "�\n",
    "⋅\n",
    "�\n",
    "�\n",
    "∂w \n",
    "i\n",
    "​\n",
    " \n",
    "∂L\n",
    "​\n",
    " = \n",
    "∂a\n",
    "∂L\n",
    "​\n",
    " ⋅ \n",
    "∂z\n",
    "∂a\n",
    "​\n",
    " ⋅x \n",
    "i\n",
    "​\n",
    " \n",
    "∂\n",
    "�\n",
    "∂\n",
    "�\n",
    "=\n",
    "∂\n",
    "�\n",
    "∂\n",
    "�\n",
    "⋅\n",
    "∂\n",
    "�\n",
    "∂\n",
    "�\n",
    "∂b\n",
    "∂L\n",
    "​\n",
    " = \n",
    "∂a\n",
    "∂L\n",
    "​\n",
    " ⋅ \n",
    "∂z\n",
    "∂a\n",
    "​\n",
    " \n",
    "Parameter Updates:\n",
    "After calculating the gradients of the loss with respect to the weights and biases, we update the model's parameters using an optimization algorithm such as stochastic gradient descent (SGD) or its variants. The updates are performed iteratively during the training process to minimize the loss function and improve the model's performance on the task.\n",
    "\n",
    "This process of backward propagation and parameter updates is repeated over multiple epochs until the model converges to a state where the loss is minimized, and the model's predictions are accurate on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8536b1-584a-4bbe-9416-2b241174b444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde06385-f23f-431e-828e-5778bc46868e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "The chain rule is a fundamental rule of calculus that allows us to find the derivative of a composition of functions. It is an essential concept in calculus and is widely used in various mathematical and scientific fields. In the context of neural networks, the chain rule is a crucial tool for calculating gradients during backward propagation, enabling the optimization of the model's parameters.\n",
    "\n",
    "The Chain Rule:\n",
    "Suppose we have two functions \n",
    "�\n",
    "=\n",
    "�\n",
    "(\n",
    "�\n",
    ")\n",
    "y=f(u) and \n",
    "�\n",
    "=\n",
    "�\n",
    "(\n",
    "�\n",
    ")\n",
    "u=g(x), where \n",
    "�\n",
    "y and \n",
    "�\n",
    "u are dependent variables, and \n",
    "�\n",
    "x is an independent variable. The chain rule states that the derivative of the composite function \n",
    "�\n",
    "=\n",
    "�\n",
    "(\n",
    "�\n",
    "(\n",
    "�\n",
    ")\n",
    ")\n",
    "y=f(g(x)) with respect to \n",
    "�\n",
    "x is the product of the derivatives of \n",
    "�\n",
    "f with respect to its input (\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "du\n",
    "df\n",
    "​\n",
    " ) and \n",
    "�\n",
    "g with respect to \n",
    "�\n",
    "x (\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "dx\n",
    "dg\n",
    "​\n",
    " ):\n",
    "\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "=\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "⋅\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "dx\n",
    "dy\n",
    "​\n",
    " = \n",
    "du\n",
    "dy\n",
    "​\n",
    " ⋅ \n",
    "dx\n",
    "du\n",
    "​\n",
    " \n",
    "The chain rule can be extended to more than two nested functions as well, in which case the derivatives of each successive function are multiplied together to find the derivative of the overall composition.\n",
    "\n",
    "Application in Backward Propagation:\n",
    "In neural networks, during forward propagation, the input data is passed through multiple layers of interconnected neurons. Each neuron applies a weighted sum of inputs and biases and then passes the result through an activation function. The output of each layer becomes the input to the next layer.\n",
    "\n",
    "During backward propagation (backpropagation), the goal is to calculate the gradients of the loss function with respect to the model's parameters (weights and biases). The chain rule is applied to efficiently compute these gradients as the error is propagated back through the layers of the network.\n",
    "\n",
    "Consider the following steps in backward propagation for a single neuron in the network:\n",
    "\n",
    "Calculate the gradient of the loss with respect to the output of the neuron (\n",
    "∂\n",
    "�\n",
    "∂\n",
    "�\n",
    "∂a\n",
    "∂L\n",
    "​\n",
    " ).\n",
    "Calculate the gradient of the output of the neuron with respect to the weighted sum (\n",
    "∂\n",
    "�\n",
    "∂\n",
    "�\n",
    "∂z\n",
    "∂a\n",
    "​\n",
    " ), which is the derivative of the activation function used in the forward propagation.\n",
    "Calculate the gradients of the loss with respect to the weights and biases (\n",
    "∂\n",
    "�\n",
    "∂\n",
    "�\n",
    "�\n",
    "∂w \n",
    "i\n",
    "​\n",
    " \n",
    "∂L\n",
    "​\n",
    "  and \n",
    "∂\n",
    "�\n",
    "∂\n",
    "�\n",
    "∂b\n",
    "∂L\n",
    "​\n",
    " ) using the chain rule:\n",
    "∂\n",
    "�\n",
    "∂\n",
    "�\n",
    "�\n",
    "=\n",
    "∂\n",
    "�\n",
    "∂\n",
    "�\n",
    "⋅\n",
    "∂\n",
    "�\n",
    "∂\n",
    "�\n",
    "⋅\n",
    "�\n",
    "�\n",
    "∂w \n",
    "i\n",
    "​\n",
    " \n",
    "∂L\n",
    "​\n",
    " = \n",
    "∂a\n",
    "∂L\n",
    "​\n",
    " ⋅ \n",
    "∂z\n",
    "∂a\n",
    "​\n",
    " ⋅x \n",
    "i\n",
    "​\n",
    " \n",
    "∂\n",
    "�\n",
    "∂\n",
    "�\n",
    "=\n",
    "∂\n",
    "�\n",
    "∂\n",
    "�\n",
    "⋅\n",
    "∂\n",
    "�\n",
    "∂\n",
    "�\n",
    "∂b\n",
    "∂L\n",
    "​\n",
    " = \n",
    "∂a\n",
    "∂L\n",
    "​\n",
    " ⋅ \n",
    "∂z\n",
    "∂a\n",
    "​\n",
    " \n",
    "The chain rule allows us to break down the computation of gradients layer by layer, efficiently calculating the contribution of each parameter to the overall loss. This process is repeated for each layer, propagating the gradients backward through the network until the input layer is reached.\n",
    "\n",
    "The computed gradients are then used to update the model's parameters using an optimization algorithm (e.g., stochastic gradient descent) to minimize the loss function and improve the model's performance on the task. The chain rule enables effective gradient calculations, making backpropagation a powerful algorithm for training neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59bf566-fbd9-4767-b39f-f9a7cc6b4766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06333e7-2917-430f-911e-608e9dcc008e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3494b83-4bd3-4bad-8da2-17d51adc8f4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2b3987-a5e6-4883-8911-a867f003deaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf19722-5aad-4764-b06b-d7873eaa0992",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d31e948-87f2-49c3-9842-7a479bab8a4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad07a15-f688-47fb-8de0-b51afd8c5254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c36c042-9a77-4b1e-bdb9-924771ec3820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cece173-329c-47ff-8d8a-c370a65d384e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
