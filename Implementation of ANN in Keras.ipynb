{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04212d07-0043-4c04-8079-254f0c1a47f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b54180-eb95-43ed-9436-19cf6d3ced7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the latest versions of TensorFlow and Keras (if not already installed)\n",
    "!pip install --upgrade tensorflow\n",
    "!pip install --upgrade keras\n",
    "\n",
    "# Load TensorFlow and Keras\n",
    "import tensorflow as tf\n",
    "from keras import __version__ as keras_version\n",
    "\n",
    "# Print the versions\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Keras version:\", keras_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b24d68d-9e14-4faa-949e-287637f89425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56a6162-e812-4d7f-bc83-2ddddaba9892",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "\n",
    "# Load the Wine Quality dataset\n",
    "wine_data = load_wine()\n",
    "\n",
    "# Check the dimensions of the dataset\n",
    "data_shape = wine_data.data.shape\n",
    "print(\"Number of samples:\", data_shape[0])\n",
    "print(\"Number of features:\", data_shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193b9df4-d4bd-457b-8d6b-3a0ca32293df",
   "metadata": {},
   "outputs": [],
   "source": [
    "This code snippet imports the load_wine function from scikit-learn and uses it to load the Wine Quality dataset. We then check the dimensions of the dataset using the shape attribute of the data array, which contains the input features of the dataset.\n",
    "\n",
    "The output will show the number of samples (rows) and the number of features (columns) in the Wine Quality dataset. Please note that the Wine Quality dataset may have been updated or moved to another library since my last update. In such cases, you can find the dataset's current location and usage instructions from the official documentation of the respective library or source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba40380-9332-4e73-b94a-67118e6050c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62be20b1-a2ff-4f56-95e9-b14fa49476de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris_data = load_iris()\n",
    "\n",
    "# Convert the dataset to a pandas DataFrame for easier manipulation\n",
    "df = pd.DataFrame(data=iris_data.data, columns=iris_data.feature_names)\n",
    "\n",
    "# Check for null values\n",
    "null_values = df.isnull().sum()\n",
    "print(\"Null values in the dataset:\")\n",
    "print(null_values)\n",
    "\n",
    "# Identify categorical variables\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "print(\"Categorical variables:\")\n",
    "print(categorical_cols)\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "for col in categorical_cols:\n",
    "    df[col] = label_encoder.fit_transform(df[col])\n",
    "\n",
    "# Show the first few rows of the encoded DataFrame\n",
    "print(\"\\nEncoded DataFrame:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a039ebc4-4018-498c-9af4-833f14bd38bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166da6ef-76ba-47b6-a857-5aaa74ebb73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "# Load the Wine Quality dataset\n",
    "wine_data = load_wine()\n",
    "\n",
    "# Convert the dataset to a pandas DataFrame for easier manipulation\n",
    "df = pd.DataFrame(data=wine_data.data, columns=wine_data.feature_names)\n",
    "\n",
    "# Separate features and target variables\n",
    "X = df  # Features (input variables)\n",
    "y = wine_data.target  # Target variable\n",
    "\n",
    "# Show the first few rows of the features (X) and target (y) variables\n",
    "print(\"Features (X):\")\n",
    "print(X.head())\n",
    "print(\"\\nTarget (y):\")\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2435f5fb-32c2-44a4-9d7b-8d250e343377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0713a6df-7d00-4fe3-a33e-8e83d3b086a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the Wine Quality dataset\n",
    "wine_data = load_wine()\n",
    "\n",
    "# Convert the dataset to a pandas DataFrame for easier manipulation\n",
    "df = pd.DataFrame(data=wine_data.data, columns=wine_data.feature_names)\n",
    "target = wine_data.target\n",
    "\n",
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split the training set into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
    "\n",
    "# Show the dimensions of the datasets\n",
    "print(\"Training set - Features:\", X_train.shape, \"Labels:\", y_train.shape)\n",
    "print(\"Validation set - Features:\", X_val.shape, \"Labels:\", y_val.shape)\n",
    "print(\"Test set - Features:\", X_test.shape, \"Labels:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff850cfe-1588-4ad1-a44b-9a495ea19624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d50eba-6834-4596-8386-3ef3b200adc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the Wine Quality dataset\n",
    "wine_data = load_wine()\n",
    "\n",
    "# Convert the dataset to a pandas DataFrame for easier manipulation\n",
    "df = pd.DataFrame(data=wine_data.data, columns=wine_data.feature_names)\n",
    "target = wine_data.target\n",
    "\n",
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split the training set into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
    "\n",
    "# Scale the dataset using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Show the first few rows of the scaled training set\n",
    "print(\"Scaled Training Set:\")\n",
    "print(pd.DataFrame(X_train_scaled, columns=wine_data.feature_names).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3327cb-085a-4071-9a5a-0a525d5a0608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121fc963-74df-49aa-8cc9-0e66923438cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Generate a hypothetical binary dataset for demonstration\n",
    "X, y = make_classification(n_samples=1000, n_features=8, n_classes=2, n_informative=5, random_state=42)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the input features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Design and build the neural network\n",
    "model = Sequential()\n",
    "\n",
    "# Add two hidden layers with 32 neurons each and ReLU activation\n",
    "model.add(Dense(32, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# Add the output layer with 1 neuron (for binary classification) and sigmoid activation\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model with binary cross-entropy loss and Adam optimizer\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.1, verbose=1)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(f\"Test loss: {loss:.4f}, Test accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01a2108-2914-4e4e-9f61-23679804eb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e655634-f6ea-4f22-983c-fea346a59f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff00b3b-a6a8-4fbf-b4b9-fe846800b01c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dc0254-73c6-4095-96b9-73e04ca2ed1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37073ace-3aaf-418c-9177-96d282508994",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b086662f-be99-41c2-9a8e-2eb0abc2646b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f2cbd5-688f-4587-8a8e-6f5a73e86f48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97e255a-43dc-4573-9edd-b37eb3f96f19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b559592c-5c56-47b1-8d24-6fc2424b264d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4978c6-bb98-4cb2-8199-1d0f22a491ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfa2a4e-65cf-46d3-bbc3-ce2e1e1fef85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eebd5ce-2cb8-4636-9c52-3d0695ba4a17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a0455d-aa1b-4eaa-804a-7f030b142aad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9745734-05fb-49b9-9f2a-98a3daeff9e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe32967-41a0-4c01-b89f-3e23fe7a12cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cc907b-61b1-475e-99df-f77d45ea0366",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fa708f-1ffb-424c-b17f-05e58a23c288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dff54ec-2225-4dad-a5ef-4821228118a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5078d075-2fa1-4f6b-a0fc-f0dbed672cff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5868784d-1c47-44f4-b6f7-8876a3b7d2a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b02315-e84a-4da3-b34e-d6d6e89c41db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e59e388-4248-4e82-b6a4-29682b931d2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb2d793-11c1-49b4-8b9b-97d1e2fd2baf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe23c430-a5ec-4841-8c23-cc617bb60428",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5670e0-242c-4b93-84d0-8723c4771c3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5711e17d-b621-4b8b-b74f-59902289ba02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a6d39f-c4c7-4fbd-9ba5-9cfda4d25eed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97e2653-2b24-402c-bf5e-acb8a5d5ef72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565f15e3-d1d1-4f41-913c-2e16928338d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68903e80-40c2-44af-a8b9-f1793faf3493",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d293ff7-6d9c-4c04-b1c0-a58fa2e09f80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239e1a1f-d629-4be8-80a0-17cc6720aa14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539e5fe9-a1d1-42e2-a944-761b5868c2e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36ecb05-7ab6-4ffa-9d88-1cb8c779fbcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062f66d7-9788-469a-9d86-2d77590ebf2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969dd488-bbfb-4b6e-a42d-ba9e0e1952a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
