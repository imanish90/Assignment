{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a072918-0eb1-434d-a599-a27d59f0f274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab1eb73-a829-45d6-a057-5b639650185d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANOVA (Analysis of Variance) is a statistical technique used to analyze the differences among means of two or more groups. It tests whether the means of the groups are significantly different from each other or not. ANOVA makes several assumptions about the data that must be met for the results to be valid. These assumptions include:\n",
    "\n",
    "Independence: The observations in each group must be independent of each other. This means that the values of one observation should not influence the values of another observation in the same group.\n",
    "\n",
    "Normality: The data within each group should be normally distributed. This means that the distribution of scores in each group should be bell-shaped.\n",
    "\n",
    "Homogeneity of variances: The variances of the groups should be equal. This means that the spread of the scores in each group should be similar.\n",
    "\n",
    "Examples of violations that could impact the validity of ANOVA results include:\n",
    "\n",
    "Violation of independence: If the observations in the groups are not independent, it can lead to biased estimates of the treatment effects. For example, in a study where siblings are in different treatment groups, the observations may not be independent, as the siblings may share similar genetic and environmental factors.\n",
    "\n",
    "Violation of normality: If the data within each group is not normally distributed, it can lead to inaccurate results. For example, if the data is skewed or has outliers, it can affect the distribution of the scores and lead to non-normality.\n",
    "\n",
    "Violation of homogeneity of variances: If the variances of the groups are not equal, it can affect the accuracy of the results. For example, if one group has a larger spread of scores than the other groups, it can lead to an overestimation of the treatment effect in that group.\n",
    "\n",
    "In conclusion, ANOVA requires several assumptions to be met for the results to be valid. Violations of these assumptions can lead to inaccurate results and conclusions. Therefore, it is important to check for these violations before interpreting the results of an ANOVA analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a237e976-215e-4bfd-a9a0-555585a02554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd01992f-6329-4b51-8294-2127c09f0fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "The three types of ANOVA are:\n",
    "\n",
    "One-way ANOVA: It is used when comparing the means of two or more groups that are independent and categorical. In a one-way ANOVA, a single factor or variable is considered, and the data is grouped into categories based on this variable.\n",
    "For example, a one-way ANOVA can be used to compare the average weight loss among three different diets (low-carb, low-fat, and balanced diet) in a weight loss study.\n",
    "\n",
    "Two-way ANOVA: It is used when comparing the means of two or more groups that are independent and categorical, while considering the influence of two independent variables or factors on the dependent variable.\n",
    "For example, a two-way ANOVA can be used to compare the effectiveness of two different types of exercise (aerobic and weight training) and two different diets (low-carb and low-fat) on weight loss in a weight loss study.\n",
    "\n",
    "Repeated measures ANOVA: It is used when the same subjects are measured on a continuous dependent variable over multiple time points or conditions.\n",
    "For example, a repeated measures ANOVA can be used to analyze the effect of a drug on blood pressure over several time points in a clinical trial.\n",
    "\n",
    "In conclusion, the type of ANOVA used depends on the research question and the type of data being analyzed. One-way ANOVA is used when comparing the means of two or more groups based on a single factor. Two-way ANOVA is used when comparing the means of two or more groups based on two independent variables or factors. Repeated measures ANOVA is used when analyzing the effect of a continuous dependent variable over multiple time points or conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a707a2c4-d59f-49c0-b8e8-c70e0e95e062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14308d6f-4e8f-46f9-a0d3-b27b65cbfc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "The partitioning of variance in ANOVA refers to the process of dividing the total variance of the dependent variable into different components or sources of variation. This is done to determine the extent to which each of these components contributes to the observed differences between the groups being compared.\n",
    "\n",
    "In ANOVA, the total variance of the dependent variable is decomposed into three components:\n",
    "\n",
    "Between-group variance: This component measures the variation among the means of the different groups being compared. It reflects the effect of the independent variable or factor on the dependent variable.\n",
    "\n",
    "Within-group variance: This component measures the variation within each group. It reflects the natural variability of the dependent variable within each group.\n",
    "\n",
    "Error variance: This component measures the variability that cannot be attributed to the independent variable or factor or to natural variability within the groups. It reflects the variability due to measurement error or other unexplained factors.\n",
    "\n",
    "Understanding the partitioning of variance is important because it helps to identify the sources of variation that contribute to the differences among the means of the groups being compared. By identifying these sources of variation, researchers can make more accurate and precise inferences about the effect of the independent variable or factor on the dependent variable.\n",
    "\n",
    "Furthermore, understanding the partitioning of variance allows researchers to calculate various effect size measures, such as eta-squared and omega-squared, which provide information about the magnitude of the effect of the independent variable or factor on the dependent variable. These effect size measures are important for interpreting the practical significance of the findings and for comparing the results across studies.\n",
    "\n",
    "In conclusion, the partitioning of variance in ANOVA is a fundamental concept that helps to identify the sources of variation that contribute to the observed differences among the groups being compared. It is important for making accurate and precise inferences about the effect of the independent variable or factor on the dependent variable and for interpreting the practical significance of the findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a82168c-a562-4502-ae4c-1e7fb702243f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae0f840-733c-41f7-85eb-62649c0598a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "In Python, you can calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using the scipy.stats module. Here's an example code snippet:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c468337-36ed-4373-8cc6-6870e733c223",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Generate sample data\n",
    "group1 = [3, 4, 5, 6, 7]\n",
    "group2 = [1, 2, 3, 4, 5]\n",
    "group3 = [7, 8, 9, 10, 11]\n",
    "\n",
    "# Combine the data into a single array\n",
    "data = group1 + group2 + group3\n",
    "\n",
    "# Calculate the overall mean\n",
    "mean = sum(data) / len(data)\n",
    "\n",
    "# Calculate the total sum of squares (SST)\n",
    "SST = sum([(x - mean)**2 for x in data])\n",
    "\n",
    "# Calculate the group means\n",
    "group_means = [sum(group)/len(group) for group in [group1, group2, group3]]\n",
    "\n",
    "# Calculate the explained sum of squares (SSE)\n",
    "SSE = sum([len(group)*(mean - group_mean)**2 for group, group_mean in zip([group1, group2, group3], group_means)])\n",
    "\n",
    "# Calculate the residual sum of squares (SSR)\n",
    "SSR = SST - SSE\n",
    "\n",
    "print(\"SST:\", SST)\n",
    "print(\"SSE:\", SSE)\n",
    "print(\"SSR:\", SSR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2920ad3b-426b-443e-b8e7-09527b87a122",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this example, we first generate some sample data for three groups (group1, group2, and group3), and then combine the data into a single array. We then calculate the overall mean of the data and use it to compute the total sum of squares (SST) using a list comprehension. Next, we calculate the means for each of the three groups and use them to compute the explained sum of squares (SSE) using another list comprehension. Finally, we calculate the residual sum of squares (SSR) by subtracting SSE from SST.\n",
    "\n",
    "Note that the stats.f_oneway() function in scipy.stats can also be used to calculate these values in a one-liner, given the data for each group. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e34e289-7974-45b3-97b6-58fd7ee4b039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Generate sample data\n",
    "group1 = [3, 4, 5, 6, 7]\n",
    "group2 = [1, 2, 3, 4, 5]\n",
    "group3 = [7, 8, 9, 10, 11]\n",
    "\n",
    "# Calculate SST, SSE, and SSR using f_oneway()\n",
    "SST, p_value = stats.f_oneway(group1, group2, group3)\n",
    "SSE = sum([(x - group_means[i])**2 for i, group in enumerate([group1, group2, group3]) for x in group])\n",
    "SSR = SST - SSE\n",
    "\n",
    "print(\"SST:\", SST)\n",
    "print(\"SSE:\", SSE)\n",
    "print(\"SSR:\", SSR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9644ed5-cc31-4da0-8b84-b1fe53ea863a",
   "metadata": {},
   "outputs": [],
   "source": [
    "This code generates the same sample data as before and then calculates SST, SSE, and SSR using the f_oneway() function. Note that SSE is calculated using a nested list comprehension that computes the sum of squared deviations from the group means for each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a13bf5-27aa-461a-a012-f0b80d736de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0071e6b9-1d5b-4dd7-b0f2-b2d4514095d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "In a two-way ANOVA, the main effects refer to the effect of each independent variable separately, while the interaction effect refers to the joint effect of the two independent variables. Here's how you can calculate the main effects and interaction effects using Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947753f0-882a-4bd7-a46f-60da419884e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Load sample data into a Pandas dataframe\n",
    "data = pd.read_csv('sample_data.csv')\n",
    "\n",
    "# Fit the ANOVA model using the ols() function from statsmodels\n",
    "model = ols('dependent_variable ~ independent_variable1 + independent_variable2 + independent_variable1 * independent_variable2', data=data).fit()\n",
    "\n",
    "# Calculate the main effect of independent_variable1\n",
    "main_effect1 = model.f_test([0, 1, 0, 0])\n",
    "\n",
    "# Calculate the main effect of independent_variable2\n",
    "main_effect2 = model.f_test([0, 0, 1, 0])\n",
    "\n",
    "# Calculate the interaction effect between independent_variable1 and independent_variable2\n",
    "interaction_effect = model.f_test([0, 0, 0, 1])\n",
    "\n",
    "# Print the results\n",
    "print(\"Main effect of independent_variable1:\", main_effect1)\n",
    "print(\"Main effect of independent_variable2:\", main_effect2)\n",
    "print(\"Interaction effect:\", interaction_effect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3547fee-55b0-419e-8090-041aaa33bbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this example, we first load the sample data into a Pandas dataframe. We then use the ols() function from the statsmodels module to fit the ANOVA model to the data. Note that we specify the formula for the model using a string, where the dependent variable is on the left-hand side of the formula, and the independent variables are on the right-hand side, separated by a + sign. We also include an interaction term between the two independent variables by multiplying them together with a * sign.\n",
    "\n",
    "Once we have fit the model, we can use the f_test() method of the model object to calculate the main effect of independent_variable1, the main effect of independent_variable2, and the interaction effect between independent_variable1 and independent_variable2. We pass a list of coefficients to the f_test() method, where each element in the list corresponds to a coefficient in the formula, in the order they appear.\n",
    "\n",
    "Note that the ols() function automatically includes an intercept term in the model, so we do not need to specify it explicitly. Also note that we can use the summary() method of the model object to obtain more detailed output about the ANOVA results, including F-statistics, p-values, and effect sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff7b5e3-4e70-4bef-875b-886496555540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14458595-2bbb-452d-850e-469de1d74e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "If you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02, this suggests that there is a statistically significant difference between the groups being compared. Specifically, it indicates that the variation between the means of the groups is larger than the variation within the groups.\n",
    "\n",
    "A p-value of 0.02 means that there is a 2% chance of obtaining the observed F-statistic or a more extreme value, assuming that there is no true difference between the groups. This is below the conventional threshold for statistical significance of 0.05, so we would reject the null hypothesis of no differences between the groups and conclude that there is a statistically significant difference between at least two of the groups being compared.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8566747-f07d-4cd6-b023-fb64bfe8ab9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c52881-9a56-4017-bdaa-724439c7d5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Handling missing data is an important consideration when conducting a repeated measures ANOVA, as missing data can reduce statistical power and bias the results. Here are some ways to handle missing data in a repeated measures ANOVA:\n",
    "\n",
    "Complete-case analysis: In this approach, only complete cases (i.e., cases with no missing data) are included in the analysis. This is the simplest method, but it can result in a loss of statistical power if a large proportion of the data is missing.\n",
    "\n",
    "Pairwise deletion: In this approach, each pairwise comparison is made using only the available data for that comparison. This can increase statistical power compared to complete-case analysis, but it can also introduce bias if the missing data are not missing completely at random.\n",
    "\n",
    "Imputation: In this approach, missing data are replaced with estimated values. There are several methods for imputation, including mean imputation, regression imputation, and multiple imputation. Imputation can increase statistical power and reduce bias compared to complete-case analysis and pairwise deletion, but it requires making assumptions about the missing data mechanism and the distribution of the data.\n",
    "\n",
    "The potential consequences of using different methods to handle missing data include:\n",
    "\n",
    "Bias: If the missing data are not missing completely at random, complete-case analysis and pairwise deletion can introduce bias into the analysis. Imputation methods can reduce bias, but they require making assumptions about the missing data mechanism and the distribution of the data.\n",
    "\n",
    "Loss of statistical power: Complete-case analysis and pairwise deletion can result in a loss of statistical power if a large proportion of the data is missing. Imputation can increase statistical power, but it can also introduce additional uncertainty.\n",
    "\n",
    "Variability in results: Different methods of handling missing data can lead to different results, which can create confusion and make it difficult to compare results across studies.\n",
    "\n",
    "In general, it is important to carefully consider the missing data mechanism and the potential consequences of different methods for handling missing data when conducting a repeated measures ANOVA. Additionally, it is important to report any missing data and the method used to handle missing data in order to ensure transparency and reproducibility of the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978c69f7-1b18-40e9-8ffc-c4096d658927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d37ed2-673e-4296-aab9-6b1f2f0f811b",
   "metadata": {},
   "outputs": [],
   "source": [
    "After conducting an ANOVA, post-hoc tests can be used to determine which groups differ significantly from each other. Some common post-hoc tests include:\n",
    "\n",
    "Tukey's Honestly Significant Difference (HSD) test: This test is used to compare all possible pairs of group means while controlling the family-wise error rate. It is typically used when there are more than two groups being compared.\n",
    "\n",
    "Bonferroni correction: This test adjusts the alpha level for multiple comparisons by dividing it by the number of comparisons being made. It is typically used when there are a small number of comparisons being made.\n",
    "\n",
    "Scheffe's test: This test controls the family-wise error rate while being more conservative than Tukey's HSD test. It is typically used when there are many groups being compared.\n",
    "\n",
    "Games-Howell test: This test does not assume equal variances between the groups and is therefore appropriate when the assumption of equal variances is violated.\n",
    "\n",
    "Dunnett's test: This test is used to compare each group mean to a control group mean.\n",
    "\n",
    "A post-hoc test might be necessary when the results of an ANOVA indicate a statistically significant difference between at least two groups, but it is not clear which specific groups differ significantly from each other. For example, suppose a researcher is studying the effect of three different treatments on blood pressure and conducts an ANOVA that shows a significant difference between the groups. A post-hoc test could be used to determine which specific treatments lead to a significant difference in blood pressure compared to the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77afcf88-8a42-46ce-8788-a06d69d84177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0017d2a8-297a-4ce6-a1fe-f1dba2fe0597",
   "metadata": {},
   "outputs": [],
   "source": [
    "Assuming the data is available in a Pandas DataFrame with the columns 'diet' and 'weight_loss', where 'diet' contains the three diet types A, B, and C, and 'weight_loss' contains the weight loss values for each participant, the following code can be used to conduct a one-way ANOVA in Python:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11de1dd3-c66c-4db2-9053-f1a709561f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# Conduct a one-way ANOVA\n",
    "f_stat, p_value = stats.f_oneway(data[data['diet'] == 'A']['weight_loss'], \n",
    "                                 data[data['diet'] == 'B']['weight_loss'], \n",
    "                                 data[data['diet'] == 'C']['weight_loss'])\n",
    "\n",
    "# Print the results\n",
    "print('F-statistic:', f_stat)\n",
    "print('p-value:', p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a5fe5a-762c-4a39-83c3-2a6075e74d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "Assuming a significance level of 0.05, we can interpret the results as follows:\n",
    "\n",
    "If the p-value is less than 0.05, we can reject the null hypothesis that there are no significant differences between the mean weight loss of the three diets. This means that there is evidence to suggest that at least one of the diets leads to a different mean weight loss compared to the others.\n",
    "\n",
    "If the p-value is greater than 0.05, we fail to reject the null hypothesis and conclude that there is insufficient evidence to suggest that there are any significant differences between the mean weight loss of the three diets.\n",
    "\n",
    "Without knowing the actual data and the resulting p-value and F-statistic, we cannot draw a conclusion about the significance of the differences between the diets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f9ed1b-3eab-4af5-a924-2342413a98a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce84e99-e98c-46d9-91f8-af9918fb22e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Assuming the data is available in a Pandas DataFrame with the columns 'program', 'experience', and 'time', where 'program' contains the three software programs A, B, and C, 'experience' contains the experience level of each employee (novice or experienced), and 'time' contains the time it took each employee to complete the task, the following code can be used to conduct a two-way ANOVA in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897d915e-d181-4eb0-9a63-c27b8ad9f9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# Fit the ANOVA model\n",
    "model = ols('time ~ C(program) + C(experience) + C(program):C(experience)', data).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Print the ANOVA table\n",
    "print(anova_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f023627-5ea5-4db4-a6ea-17804521bfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "The resulting ANOVA table will contain the F-statistics and p-values for each main effect and interaction effect, as well as the overall F-statistic and p-value for the model. Assuming a significance level of 0.05, we can interpret the results as follows:\n",
    "\n",
    "If the p-value for the main effect of software program (C(program)) is less than 0.05, we can conclude that there is a significant difference in the average time it takes to complete the task using the different software programs, after controlling for experience level.\n",
    "\n",
    "If the p-value for the main effect of experience level (C(experience)) is less than 0.05, we can conclude that there is a significant difference in the average time it takes to complete the task between novice and experienced employees, after controlling for software program.\n",
    "\n",
    "If the p-value for the interaction effect between software program and experience level (C(program):C(experience)) is less than 0.05, we can conclude that there is a significant interaction effect between software program and experience level on the average time it takes to complete the task. This means that the effect of software program on task completion time may depend on the experience level of the employee, or vice versa.\n",
    "\n",
    "Note that the interpretation of the results may vary depending on the actual values of the F-statistics and p-values obtained from the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8028d9-749f-4f90-8284-83caff2ba1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans-11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abcf735-3511-44a5-98c9-f550be482426",
   "metadata": {},
   "outputs": [],
   "source": [
    "Assuming the data is available in a Pandas DataFrame with the columns 'group' and 'score', where 'group' contains the two groups (control and experimental) and 'score' contains the test scores, the following code can be used to conduct a two-sample t-test and post-hoc test in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa935030-ed9b-41c1-a330-4912285d76e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# Separate the scores for each group\n",
    "control_scores = data[data['group'] == 'control']['score']\n",
    "experimental_scores = data[data['group'] == 'experimental']['score']\n",
    "\n",
    "# Conduct a two-sample t-test\n",
    "t_stat, p_value = stats.ttest_ind(control_scores, experimental_scores, equal_var=False)\n",
    "\n",
    "# Print the results\n",
    "print('T-statistic: {:.2f}, p-value: {:.4f}'.format(t_stat, p_value))\n",
    "\n",
    "# Conduct a post-hoc test\n",
    "tukey_results = pairwise_tukeyhsd(data['score'], data['group'], alpha=0.05)\n",
    "\n",
    "# Print the post-hoc results\n",
    "print(tukey_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8582e5-984e-4649-8e3e-64946ceb72e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "The resulting output will include the t-statistic and p-value for the two-sample t-test, as well as the results of the post-hoc test. Assuming a significance level of 0.05, we can interpret the results as follows:\n",
    "\n",
    "If the p-value for the two-sample t-test is less than 0.05, we can conclude that there is a significant difference in test scores between the control and experimental groups. This means that the new teaching method may have a significant effect on student test scores.\n",
    "\n",
    "If the post-hoc test results show significant differences between the control and experimental groups, we can use these results to determine which group(s) differ significantly from each other. For example, if the post-hoc test shows that the experimental group has significantly higher test scores than the control group, we can conclude that the new teaching method led to higher test scores compared to the traditional teaching method.\n",
    "\n",
    "Note that the interpretation of the results may vary depending on the actual values of the t-statistic and p-value obtained from the analysis, as well as the results of the post-hoc test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467984fd-9fda-4b2b-a363-62ec7cd79f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001166f5-2d70-46d0-87dc-f56d4b787b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "A repeated measures ANOVA is not appropriate for this scenario, as it is used for analyzing data where the same individuals are measured multiple times under different conditions. Instead, a one-way ANOVA can be used to compare the mean sales of the three stores.\n",
    "\n",
    "Here is how to conduct a one-way ANOVA in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4ea533-bec7-4603-8e9d-b15858915f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "# create a DataFrame with the sales data\n",
    "data = {'Store A': [100, 110, 95, 105, 120, 130, 125, 140, 135, 130, 125, 130, 135, 140, 145, 140, 135, 130, 125, 120, 115, 110, 105, 100, 95, 90, 85, 80, 75, 70],\n",
    "        'Store B': [80, 85, 90, 95, 100, 105, 110, 115, 120, 125, 120, 115, 110, 105, 100, 95, 90, 85, 80, 75, 70, 65, 60, 55, 50, 45, 40, 35, 30, 25],\n",
    "        'Store C': [50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100, 105, 110, 115, 120, 125, 130, 125, 120, 115, 110, 105, 100, 95, 90, 85, 80, 75, 70, 65]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# conduct the one-way ANOVA\n",
    "f_stat, p_val = stats.f_oneway(df['Store A'], df['Store B'], df['Store C'])\n",
    "\n",
    "# print the results\n",
    "print(\"F-statistic:\", f_stat)\n",
    "print(\"p-value:\", p_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaf71cc-0a63-4ff9-a95e-5fea3cea0e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "The output will show the F-statistic and p-value for the ANOVA. If the p-value is less than 0.05, we can reject the null hypothesis and conclude that there are significant differences in the average daily sales between at least two of the three stores.\n",
    "\n",
    "If the results are significant, we can conduct a post-hoc test, such as Tukey's HSD test or Bonferroni correction, to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c034a21-f728-4b30-9979-b4aae50ab193",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba4477c-7207-4644-aad2-205a01458c16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f270fdad-cbf8-461b-86cb-3948a878f5e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
